{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e37c65cf",
   "metadata": {},
   "source": [
    "### **Attention is a technique that lets a model focus on the most relevant parts of the input when producing an output ‚Äî instead of treating everything as equally important.**\n",
    "\n",
    "- Think of it like how humans read:\n",
    "When you read a sentence, you don‚Äôt remember every word equally ‚Äî your brain pays more attention to the important words.\n",
    "\n",
    " Simple Example (Human-style):\n",
    "\n",
    "Sentence: ‚ÄúThe cat sat on the mat because it was tired.‚Äù\n",
    "\n",
    "Question: What does ‚Äúit‚Äù refer to?\n",
    "\n",
    "Your brain instantly links ‚Äúit‚Äù ‚Üí ‚Äúcat‚Äù, not ‚Äúmat‚Äù."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9c3a12",
   "metadata": {},
   "source": [
    "### **Types of attention mechanisms:-** \n",
    "1. Simplified Self-Attention (Each word decides which other words are important)\n",
    "\n",
    "2. Self-Attention (Each word uses query, key, and value to understand context from all words)\n",
    "\n",
    "3. Causal Attention (Each word can attend only to past words, not future ones)\n",
    "\n",
    "4. Multi-Head Attention (Multiple attention heads look at the same sentence from different perspectives)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc37c95a",
   "metadata": {},
   "source": [
    "<div class= \"alert alert-block\">\n",
    "\n",
    "### **1. Simplified Self-Attention means:**\n",
    "\n",
    "- Each word looks at other words in the same sentence\n",
    "\n",
    "- It decides which words are important for understanding meaning\n",
    "\n",
    "- Every word builds its meaning using context from related words\n",
    "\n",
    "*Example:*\n",
    "\n",
    "‚ÄúI went to the bank to deposit money‚Äù\n",
    "\n",
    "The word ‚Äúbank‚Äù checks all other words\n",
    "\n",
    "It gives high attention to:  ‚Äúdeposit‚Äù, ‚Äúmoney‚Äù\n",
    "\n",
    "It gives low attention to:  ‚Äúriver‚Äù (not present, but possible meaning)\n",
    "\n",
    "- So the model understands bank = financial bank, not river bank\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66efdd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "inputs = torch.tensor([\n",
    "    [0.43, 0.15, 0.89], # your\n",
    "    [0.55, 0.87, 0.66], # journey\n",
    "    [0.57, 0.85, 0.64], # starts\n",
    "    [0.22, 0.58, 0.33], # with\n",
    "    [0.77, 0.25, 0.10], # one\n",
    "    [0.05, 0.80, 0.55] # step\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "220b6aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1]\n",
    "\n",
    "attention_score = torch.empty(inputs.shape[0])\n",
    "for i, x_i in enumerate(inputs):\n",
    "    attention_score[i] = torch.dot(x_i, query)\n",
    "\n",
    "print(attention_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03c14f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights :  tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
      "Sum :  tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "attention_weights = attention_score/attention_score.sum()\n",
    "print(\"Attention weights : \", attention_weights)\n",
    "print(\"Sum : \", attention_weights.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22e3ade6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights :  tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum :  tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "attention_weights_2 = torch.softmax(attention_score, dim=0)\n",
    "print(\"Attention weights : \", attention_weights_2)\n",
    "print(\"Sum : \", attention_weights_2.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9c62a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
       "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
       "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
       "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
       "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
       "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_scores = torch.zeros(6, 6)\n",
    "for i, x_i in enumerate(inputs):        # using two for loops are generally slow\n",
    "    for j, x_j in enumerate(inputs):\n",
    "        attention_scores[i, j] = torch.dot(x_i, x_j)\n",
    "\n",
    "attention_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07a4c80",
   "metadata": {},
   "source": [
    "#### **instead of all of this, we can simply do the matrix multiplication of input with transpose of input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4d5acc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
       "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
       "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
       "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
       "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
       "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_scores =  inputs @ inputs.T   # matrix multiplication of input matrix with transpose of input matrx\n",
    "attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cb764b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
       "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
       "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
       "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
       "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
       "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights = torch.softmax(attention_scores,dim= -1)\n",
    "attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb2fd9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All rows sum :  tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "print(\"All rows sum : \", attention_weights.sum(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ae6a919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4421, 0.5931, 0.5790],\n",
       "        [0.4419, 0.6515, 0.5683],\n",
       "        [0.4431, 0.6496, 0.5671],\n",
       "        [0.4304, 0.6298, 0.5510],\n",
       "        [0.4671, 0.5910, 0.5266],\n",
       "        [0.4177, 0.6503, 0.5645]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vectors = attention_weights @ inputs\n",
    "context_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8008b04b",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block\">\n",
    "\n",
    "### **2. Self-attention means:**\n",
    "- Words attend to other words in the same sentence\n",
    "\n",
    "- Every word understands its context\n",
    "\n",
    "*Example:*\n",
    "\n",
    "‚ÄúI went to the bank to deposit money‚Äù\n",
    "\n",
    "The word ‚Äúbank‚Äù attends strongly to ‚Äúdeposit‚Äù and ‚Äúmoney‚Äù, not ‚Äúriver‚Äù\n",
    "\n",
    "In self-attention, every word is split into three roles:\n",
    "\n",
    "1Ô∏è‚É£ **Query (Q)**\n",
    "\n",
    "üëâ What this word is looking for\n",
    "\n",
    "Each word asks:\n",
    "‚ÄúWhich other words are important for me?‚Äù\n",
    "\n",
    "Query is used to search among other words.\n",
    "\n",
    "*Think:* question in your head\n",
    "\n",
    "2Ô∏è‚É£ **Key (K)**\n",
    "\n",
    "üëâ What each word represents\n",
    "\n",
    "Every word advertises what it contains\n",
    "\n",
    "Queries compare against keys to check relevance\n",
    "\n",
    "*Think:* label or identity card\n",
    "\n",
    "3Ô∏è‚É£ **Value (V)**\n",
    "\n",
    "üëâ The actual information to take\n",
    "\n",
    "If a word is important, its value is used\n",
    "\n",
    "Values are mixed to form the final meaning\n",
    "\n",
    "*Think:* actual content\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97a12f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "inputs = torch.tensor([\n",
    "    [0.43, 0.15, 0.89], # your\n",
    "    [0.55, 0.87, 0.66], # journey\n",
    "    [0.57, 0.85, 0.64], # starts\n",
    "    [0.22, 0.58, 0.33], # with\n",
    "    [0.77, 0.25, 0.10], # one\n",
    "    [0.05, 0.80, 0.55] # step\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f16e65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = inputs[1]      # second word (journey)\n",
    "d_inp = inputs.shape[1]     # input embedding size i.e 3\n",
    "d_out = 2       # output dimension size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44f3a153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.0492, 0.5989],\n",
      "        [0.1771, 0.2639],\n",
      "        [0.4717, 0.8384]])\n",
      "Parameter containing:\n",
      "tensor([[0.1639, 0.1899],\n",
      "        [0.9971, 0.5516],\n",
      "        [0.7827, 0.1247]])\n",
      "Parameter containing:\n",
      "tensor([[0.2144, 0.6680],\n",
      "        [0.4840, 0.3438],\n",
      "        [0.8777, 0.9955]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(64)\n",
    "W_query = torch.nn.Parameter(torch.rand(d_inp, d_out), requires_grad= False)\n",
    "W_key = torch.nn.Parameter(torch.rand(d_inp, d_out), requires_grad= False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_inp, d_out), requires_grad= False)\n",
    "print(W_query)\n",
    "print(W_key)\n",
    "print(W_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ade202e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5500, 0.8700, 0.6600])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = inputs @ W_query\n",
    "keys = inputs @ W_key\n",
    "values = inputs @ W_value\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e1ce240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7159, 1.3847, 1.3595, 0.8283, 0.5216, 1.1199],\n",
       "        [0.7578, 1.4675, 1.4408, 0.8779, 0.5534, 1.1866],\n",
       "        [0.7440, 1.4431, 1.4169, 0.8634, 0.5450, 1.1665],\n",
       "        [0.4014, 0.7712, 0.7570, 0.4611, 0.2887, 0.6245],\n",
       "        [0.2868, 0.5980, 0.5879, 0.3590, 0.2399, 0.4772],\n",
       "        [0.5633, 1.0631, 1.0432, 0.6351, 0.3914, 0.8636]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_scores = queries @ keys.T\n",
    "attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77ce30ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1400, 0.2059, 0.2029, 0.1493, 0.1251, 0.1767],\n",
      "        [0.1383, 0.2083, 0.2051, 0.1482, 0.1229, 0.1771],\n",
      "        [0.1387, 0.2076, 0.2045, 0.1486, 0.1236, 0.1770],\n",
      "        [0.1521, 0.1883, 0.1867, 0.1574, 0.1425, 0.1730],\n",
      "        [0.1534, 0.1836, 0.1825, 0.1599, 0.1493, 0.1712],\n",
      "        [0.1473, 0.1965, 0.1943, 0.1535, 0.1333, 0.1751]])\n"
     ]
    }
   ],
   "source": [
    "dim_key = inputs.shape[1]\n",
    "attention_weights = torch.softmax(attention_scores / dim_key**0.5, dim=-1)\n",
    "print(attention_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "50714303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8796, 1.0495],\n",
       "        [0.8820, 1.0516],\n",
       "        [0.8812, 1.0509],\n",
       "        [0.8618, 1.0342],\n",
       "        [0.8558, 1.0291],\n",
       "        [0.8707, 1.0418]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vectors = attention_weights @ values\n",
    "context_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c741f699",
   "metadata": {},
   "source": [
    "#### **now doing all the process in structure way by creating a class named SelfAttention_v1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5a4c73d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SelfAttention_v1(nn.Module):\n",
    "    def __init__(self, d_inp, d_out):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Parameter(torch.rand(d_inp, d_out))\n",
    "        self.W_key = nn.Parameter(torch.rand(d_inp, d_out))\n",
    "        self.W_value = nn.Parameter(torch.rand(d_inp, d_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = x @ self.W_key\n",
    "        queries = x @ self.W_query\n",
    "        values = x @ self.W_value\n",
    "\n",
    "        attention_scores = queries @ keys.T\n",
    "        attention_weights = torch.softmax(\n",
    "            attention_scores / keys.shape[-1]**0.5, dim= -1\n",
    "        )\n",
    "\n",
    "        context_vectors = attention_weights @ values\n",
    "        return context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2ae4ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8885, 1.0573],\n",
      "        [0.8913, 1.0598],\n",
      "        [0.8905, 1.0590],\n",
      "        [0.8669, 1.0386],\n",
      "        [0.8596, 1.0323],\n",
      "        [0.8777, 1.0479]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(64)\n",
    "self_attent_v1 = SelfAttention_v1(d_inp, d_out)\n",
    "print(self_attent_v1(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4381aaa7",
   "metadata": {},
   "source": [
    "#### **now using nn.Linear instead of nn.Parameter, contributing to more stable and effective model trainig**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8ce69b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention_v2(nn.Module):\n",
    "    def __init__(self, d_inp, d_out, qkv_bias = False):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(d_inp, d_out, bias = qkv_bias)\n",
    "        self.W_key = nn.Linear(d_inp, d_out, bias = qkv_bias)\n",
    "        self.W_value = nn.Linear(d_inp, d_out, bias = qkv_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attention_scores = queries @ keys.T\n",
    "        attention_weights = torch.softmax(\n",
    "            attention_scores / keys.shape[-1]**0.5, dim= -1\n",
    "        )\n",
    "\n",
    "        context_vectors = attention_weights @ values\n",
    "        return context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "424bf441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0401,  0.4704],\n",
      "        [-0.0400,  0.4726],\n",
      "        [-0.0400,  0.4726],\n",
      "        [-0.0393,  0.4764],\n",
      "        [-0.0405,  0.4740],\n",
      "        [-0.0389,  0.4763]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(64)\n",
    "self_attent_v2 = SelfAttention_v2(d_inp, d_out)\n",
    "print(self_attent_v2(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fb78a1",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block\">\n",
    "\n",
    "### **3. Causal Self-Attention(Masked Attention) means:**\n",
    "\n",
    "- Each word attends only to itself and previous words\n",
    "\n",
    "- A word cannot see future words\n",
    "\n",
    "- Used when generating text step-by-step\n",
    "\n",
    "*Example:* ‚ÄúI am learning deep learning‚Äù\n",
    "\n",
    "When predicting each word:\n",
    "\n",
    "-  ‚ÄúI‚Äù ‚Üí can see only ‚ÄúI‚Äù\n",
    "\n",
    "-  ‚Äúam‚Äù ‚Üí can see ‚ÄúI am‚Äù\n",
    "  \n",
    "-  ‚Äúlearning‚Äù ‚Üí can see ‚ÄúI am learning‚Äù\n",
    "  \n",
    "-  ‚Äúdeep‚Äù ‚Üí can see previous words\n",
    "  \n",
    "-  ‚Äúlearning‚Äù ‚Üí can see all previous words\n",
    "\n",
    "*But:*\n",
    "\n",
    "‚ÄúI‚Äù cannot see ‚Äúlearning‚Äù\n",
    "\n",
    "‚Äúam‚Äù cannot see ‚Äúdeep‚Äù\n",
    "\n",
    "No word can look ahead\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f5325dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1665, 0.1666, 0.1666, 0.1668, 0.1667, 0.1668],\n",
       "        [0.1665, 0.1666, 0.1666, 0.1668, 0.1667, 0.1668],\n",
       "        [0.1665, 0.1666, 0.1666, 0.1668, 0.1667, 0.1668],\n",
       "        [0.1665, 0.1666, 0.1666, 0.1668, 0.1667, 0.1668],\n",
       "        [0.1665, 0.1666, 0.1666, 0.1668, 0.1667, 0.1668],\n",
       "        [0.1665, 0.1666, 0.1666, 0.1668, 0.1667, 0.1668]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "inputs = torch.tensor([\n",
    "    [0.43, 0.15, 0.89], # your\n",
    "    [0.55, 0.87, 0.66], # journey\n",
    "    [0.57, 0.85, 0.64], # starts\n",
    "    [0.22, 0.58, 0.33], # with\n",
    "    [0.77, 0.25, 0.10], # one\n",
    "    [0.05, 0.80, 0.55] # step\n",
    "])\n",
    "\n",
    "queries = self_attent_v2(inputs)\n",
    "keys = self_attent_v2(inputs)\n",
    "attention_scores = queries @ keys.T\n",
    "attention_weights = torch.softmax(attention_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "31adc927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_length = attention_scores.shape[0]\n",
    "mask_sample = torch.tril(torch.ones(context_length, context_length))\n",
    "mask_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b4a9918c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1665, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1665, 0.1666, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1665, 0.1666, 0.1666, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1665, 0.1666, 0.1666, 0.1668, 0.0000, 0.0000],\n",
       "        [0.1665, 0.1666, 0.1666, 0.1668, 0.1667, 0.0000],\n",
       "        [0.1665, 0.1666, 0.1666, 0.1668, 0.1667, 0.1668]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_sample = attention_weights * mask_sample\n",
    "masked_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab96a837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4998, 0.5002, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3332, 0.3334, 0.3334, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2498, 0.2500, 0.2500, 0.2503, 0.0000, 0.0000],\n",
       "        [0.1998, 0.2000, 0.2000, 0.2002, 0.2001, 0.0000],\n",
       "        [0.1665, 0.1666, 0.1666, 0.1668, 0.1667, 0.1668]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_sums = masked_sample.sum(dim=1, keepdim=True)\n",
    "masked_sample_norm = masked_sample / row_sums\n",
    "masked_sample_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476a8519",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
