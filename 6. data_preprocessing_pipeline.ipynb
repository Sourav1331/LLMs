{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91983d5d",
   "metadata": {},
   "source": [
    "#### **LLM preprocessing = cleaning massive text → splitting → tokenizing → converting into numerical sequences the transformer can learn from**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5ef69f",
   "metadata": {},
   "source": [
    "### **There are four steps in LLM data preprocessing:-**\n",
    "*1. Tokenization (splitting the text into tokens, then assigning token IDs to each token)*\n",
    "\n",
    "*2. Token Embeddings (converting token IDs into dense vector representations)*\n",
    "\n",
    "*3. Positional Embeddings (encoding information about position of each token in sequence)*\n",
    "\n",
    "*4. Input Embeddings (Token Embeddings + Positional Embeddings)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73d67e4",
   "metadata": {},
   "source": [
    "#### **Files 1–5 include the data preprocessing pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b2793a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
